{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce63571f",
   "metadata": {},
   "source": [
    "### Challenge 1\n",
    "\n",
    "# Data Visualization\n",
    "\n",
    "In this notebook you'll find real-world tasks that will challenge your data visualization skills and your creativity. The idea is not only to make use of various visualization methods, but to experience the insights that can only be obtained through them and to use them as story-telling tools to communicate your findings.\n",
    "\n",
    "Our tasks are divided in three levels of difficuty. The first one requires basic skills to explore a given dataset on a pre-defined datase, the second one asks you to implement a local solution in your machine and the third one requires to deploy the solution in a clound environment. These tasks also comprise three areas of application: <u>data-exploration</u>, <u>model-understanding</u> and <u>communication of results</u>. To be able to tackle them, they require that you understand the Machine Learning concepts, performance metrics and visualization tools explained in the following guide (Approx. time to read: 3 hours):\n",
    "\n",
    "- https://pair-code.github.io/what-if-tool/learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5c348d",
   "metadata": {},
   "source": [
    "## Beginner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee141036",
   "metadata": {},
   "source": [
    "To get started, let's take a look at an article published by the People+AI Research group of Google. In this article they talk about the _hidden bias_ contained in real-world datasets used to train Machine Learning models and how these models can hurt people.\n",
    "\n",
    "- https://pair.withgoogle.com/explorables/hidden-bias\n",
    "\n",
    "Can you think of another example where hidden bias in datasets can hurt people? Other times, hidden bias don't hurt people but simply make models perform worse in the production environment than in the training environment. What could be an example of this other situation? Share your thoughts in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b26ad",
   "metadata": {},
   "source": [
    "_Your thoughts here..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a420c",
   "metadata": {},
   "source": [
    "Next, we make use of the _What-If_ tool developed by the same group. This time you'll interact with multiple classification models to predict the yearly income of a person based on their census information. Explore the different features available and how each of them affects the predictions made by the models.\n",
    "\n",
    "- https://pair-code.github.io/what-if-tool/demos/uci.html\n",
    "\n",
    "Here are a couple of questions concerning _data-exploration_ and _model-understanding_:\n",
    "- Take a look at the Features tab.\n",
    "  - Are the numerical features uniformly distributed?\n",
    "  - Which features are multimodal?\n",
    "  - Are the categorical features balanced?\n",
    "  - How would you ensure different types of features are not biased towards some values in your training dataset?\n",
    "- Which features help the models to make fairer predictions?\n",
    "- Which features have the most hidden bias that can hurt people?\n",
    "- Which model makes the most accurate predictions?\n",
    "- Which model has the best F1 score?\n",
    "- Based on two features that you choose, which model makes fairer predictions? Which features did you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5d0f5",
   "metadata": {},
   "source": [
    "_Your thoughts here..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40111e3d",
   "metadata": {},
   "source": [
    "## Intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db8f954",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2b172ab",
   "metadata": {},
   "source": [
    "## Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ee18a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
